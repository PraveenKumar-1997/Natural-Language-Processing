{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSy-sfxOsclS"
      },
      "source": [
        "# CS 447 Homework 2 $-$ Text Classification with Neural Networks\n",
        "In this homework, you will build machine learning models to detect the sentiment of movie reviews using the IMDb movie reviews dataset. Specifically, you will implement classifiers based on Convolutional Neural Networks (CNN's) and Recurrent Neural Networks (RNN's).\n",
        "\n",
        "In addition to the Pytorch tutorial we have provided on Coursera, we highly recommend that you take a look at the PyTorch tutorials before starting this assignment:\n",
        "<ul>\n",
        "<li><a href=\"https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\">https://pytorch.org/tutorials/beginner/pytorch_with_examples.html</a>\n",
        "<li><a href=\"https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\">https://pytorch.org/tutorials/beginner/data_loading_tutorial.html</a>\n",
        "<li><a href=\"https://github.com/yunjey/pytorch-tutorial\">https://github.com/yunjey/pytorch-tutorial</a>\n",
        "</ul>\n",
        "\n",
        "<font color='green'>While you work, we suggest that you keep your hardware accelerator set to \"CPU\" (the default for Colab). However, when you have finished debugging and are ready to train your models, you should select \"GPU\" as your runtime type. This will speed up the training of your models. You can find this by going to <TT>Runtime > Change Runtime Type</TT> and select \"GPU\" from the dropdown menu.</font>\n",
        "\n",
        "As usual, you should not import any other libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyCOvTRQ1nb-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a94274-47cd-4a4e-844a-1c04a21bf176"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "import torch\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "if __name__=='__main__':\n",
        "    print('Using device:', DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHbJ1-aDsWCG"
      },
      "source": [
        "# Step 1: Download the Data\n",
        "First we will download the dataset using [torchtext](https://torchtext.readthedocs.io/en/latest/index.html), which is a package that supports NLP for PyTorch. \n",
        "\n",
        "Unfortunately, you have to install the <TT>torchdata</TT> package on the Colab machine in order to access the data. To do this, run the cell below (you may need to click the \"Restart Runtime\" button when it finishes). You will have to do this every time you return to work on the homework.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rT4n4QzHAYe_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e399bfe-acee-40c8-8888-a85725d59fc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchdata\n",
            "  Downloading torchdata-0.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchdata) (2.23.0)\n",
            "Collecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 54.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchdata) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.12.1->torchdata) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2022.9.24)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 59.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (3.0.4)\n",
            "Installing collected packages: urllib3, portalocker, torchdata\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed portalocker-2.5.1 torchdata-0.4.1 urllib3-1.25.11\n"
          ]
        }
      ],
      "source": [
        "!pip install torchdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMVBA0ijAUgt"
      },
      "source": [
        "The following cell will get you `train_data` and `test_data`. It also does some basic tokenization.\n",
        "\n",
        "*   To access the list of textual tokens for the *i*th example, use `train_data[i][1]`\n",
        "*   To access the label for the *i*th example, use `train_data[i][0]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfX3bNby8FYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ae98c03-6e9b-45bd-818f-594f023205e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num. Train Examples: 20000\n",
            "Num. Test Examples: 5000\n",
            "\n",
            "SAMPLE DATA:\n",
            "Sample text: ['A', 'solid', ',', 'if', 'unremarkable', 'film', '.', 'Matthau', ',', 'as', 'Einstein', ',', 'was', 'wonderful', '.', 'My', 'favorite', 'part', ',', 'and', 'the', 'only', 'thing', 'that', 'would', 'make', 'me', 'go', 'out', 'of', 'my', 'way', 'to', 'see', 'this', 'again', ',', 'was', 'the', 'wonderful', 'scene', 'with', 'the', 'physicists', 'playing', 'badmitton', ',', 'I', 'loved', 'the', 'sweaters', 'and', 'the', 'conversation', 'while', 'they', 'waited', 'for', 'Robbins', 'to', 'retrieve', 'the', 'birdie', '.']\n",
            "Sample label: pos \n",
            "\n",
            "Sample text: ['From', 'the', 'very', 'opening', 'scene', 'you', 'will', 'notice', 'just', 'how', 'hard', 'they', 'tried', 'to', 'mimic', 'the', 'very', 'smart', 'and', 'powerful', \"'\", 'Cruel', \"Intentions'\", ',', 'and', 'how', 'flat', 'it', 'landed', '.', \"You'll\", 'also', 'notice', 'what', 'a', 'terrible', 'choice', 'they', 'made', 'by', 'casting', 'Robin', 'Dunne', 'as', 'Valmont..', '.', 'Then', 'in', 'the', 'second', 'scene', ',', 'you', 'meet', 'the', 'two', 'best', 'things', 'in', 'this', 'movie', ',', 'Amy', 'Adams', 'and', 'Mimi', 'Rogers', 'as', 'Kathryn', 'and', 'her', 'mother', '.', 'That', 'is', ',', 'if', 'you', 'can', 'get', 'past', 'the', 'fact', 'that', 'Kathryn', \"wasn't\", 'blonde', 'in', 'the', 'first', 'film..', '.', 'Then', 'the', 'movie', 'goes', 'on', ',', 'you', 'see', 'the', 'cheap', 'romantic', 'story', 'from', 'miles', 'ago', ',', 'and', 'you', 'notice', 'Sebastian', 'has', 'already', 'met', 'an', 'Anette', 'in', 'the', 'past', ',', 'here', 'called', 'Danielle', ',', 'and', 'a', 'Cecile', ',', 'here', 'called', 'Cherie..', '.', 'How', 'original', 'is', 'that', 'for', 'a', 'prequel', '.', 'Then', 'it', 'turns', 'into', 'a', 'low', 'budget', \"'\", 'Wild', 'Things', \"'\", 'type', 'of', 'film', 'with', 'lots', 'and', 'lots', 'of', 'oh-my', '\"', 'twists\"', '.', 'As', 'I', 'mentioned', ',', 'Robin', 'Dunne', 'was', 'a', 'very', 'bad', 'choice', '.', 'Not', 'that', 'he', 'is', 'a', 'bad', 'actor', ',', \"he's\", 'good.', '.', 'He', 'just', \"doesn't\", 'have', 'the', 'charisma', 'Ryan', 'did', '.', 'Amy', 'Adams', ',', 'who', 'is', 'in', 'my', 'opinion', 'one', 'of', 'the', 'most', 'talented', 'young', 'actresses', 'of', 'our', 'time', ',', 'once', 'again', 'delivers', '.', 'But', 'with', 'all', 'the', 'talent', 'in', 'the', 'world', ',', 'there', 'is', 'no', 'way', 'one', 'could', 'save', 'this', 'trash', '.', 'As', 'a', 'whole', ',', 'this', '\"', 'movie', '\"', 'feels', 'like', 'a', \"'\", 'Beverly', 'Hills', ',', '90210', \"'\", 'episode', '.', 'The', 'score', 'has', 'been', 'stolen', 'from', \"'\", 'Cruel', 'Intentions', \"'\", 'and', \"'\", \"Jawbreaker'..\", '.', 'Yes', ',', 'they', 'used', 'the', 'score', 'from', 'JAWBREAKER..', '.', \"Couldn't\", 'they', 'at', 'least', 'leave', 'that', 'one', 'alone?', '!', \"You'll\", 'want', 'to', 'pass', 'this', 'one', '.', 'If', 'you', 'want', 'more', 'Cruel', 'Intentions', ',', 'watch', 'Stephen', 'Frears', \"'\", 'Dangerous', 'Liaisons', '.']\n",
            "Sample label: neg \n",
            "\n",
            "Sample text: ['BRIEF', 'ENCOUNTER', 'is', 'a', 'ghastly', 'and', 'pointless', 'remake', 'of', 'the', '1945', 'David', 'Lean', 'classic', ',', 'which', 'was', 'based', 'on', 'Noel', \"Coward's\", 'play', '\"', 'Still', 'Life\"', '.', 'A', 'doctor', 'removes', 'a', 'particle', 'of', 'grit', 'from', 'a', \"woman's\", 'eye', 'at', 'a', 'railway', 'station', ',', 'he', 'is', 'in', 'a', 'miserable', 'relationship', ',', 'she', 'is', 'happily', 'married', 'social', 'worker', 'of', 'Italian', 'ancestry', '.', 'They', 'meet', 'by', 'accident', 'on', 'another', 'occasion', ',', 'form', 'an', 'instant', 'attraction', 'and', 'arrange', 'to', 'meet', 'each', 'other', 'every', 'Wednesday', '.', 'The', 'pair', 'fall', 'in', 'love', ',', 'but', 'after', 'spending', 'a', 'few', 'afternoons', 'together', 'they', 'realise', 'that', 'they', 'have', 'no', 'realistic', 'chance', 'of', 'happiness', 'and', 'agree', 'to', 'part', '.', \"Coward's\", 'original', 'one-act', 'play', 'concerned', 'two', 'ordinary', 'people', 'who', 'fall', 'in', 'love', '.', 'Sophia', 'Loren', 'and', 'Richard', 'Burton', ',', 'two', 'Super', 'Stars', 'and', 'veterans', 'of', 'Hollywood', 'Epics', ',', 'are', \"nobody's\", 'idea', 'of', \"'\", 'ordinary', \"people'\", '.', 'Loren', 'in', 'particular', 'is', 'miscast', '-', 'Sophia', 'Loren', 'in', 'full', 'make-up', ',', 'looking', 'like', 'a', 'million', 'dollars', ',', 'working', 'as', 'a', 'part-time', 'voluntary', 'social', 'worker', 'at', 'a', 'Citizen', 'Advice', 'Bureau', 'just', \"doesn't\", 'ring', 'true', '.', 'Burton', ',', 'looking', 'haggard', ',', 'with', 'dyed', 'hair', ',', 'too', 'much', 'make-up', 'and', 'wearing', 'platform', 'shoes', ',', \"doesn't\", 'come', 'across', 'as', 'your', 'average', 'General', 'Practitioner', '.', 'That', 'said', ',', 'you', \"can't\", 'really', 'blame', 'them', 'for', 'having', 'an', 'affair', 'after', 'seeing', 'their', 'spouses', '.', 'Burton', 'is', 'married', 'to', 'a', 'literary', 'critic', 'who', 'spends', 'her', 'evenings', 'penning', 'poisonous', 'reviews', 'and', 'who', 'treats', 'her', 'husband', 'with', 'total', 'contempt', '.', \"Loren's\", 'husband', ',', 'Jack', 'Hedley', ',', 'potters', 'around', 'the', 'house', 'all', 'day', 'and', 'is', 'terminally', 'boring', ':', 'the', 'most', 'exciting', 'thing', 'he', 'has', 'ever', 'done', 'is', 'nearly', 'have', 'an', 'affair', 'six', 'years', 'previous', '.', 'Their', 'final', 'scene', 'together', 'will', 'induce', 'nausea', ',', '(', '\"You\\'ve', 'been', 'a', 'long', ',', 'long', 'way', 'away\"', ',', 'etc.)', '.', 'That', 'great', 'British', 'jobbing', 'actor', ',', 'John', 'LeMesurier', ',', 'has', 'a', 'three', 'minute', 'cameo', 'as', \"Burton's\", 'friend', ',', 'and', 'appears', 'to', 'be', 'slightly', 'inebriated', ',', 'speaking', 'his', 'lines', 'in', 'a', 'barely', 'audible', 'voice', '.', \"It's\", 'a', 'sad', 'and', 'forgettable', 'performance', 'in', 'a', 'dismal', ',', 'awful', 'rehash', 'of', 'a', 'cinema', 'classic', '.', 'Avoid', 'at', 'all', 'costs', '.']\n",
            "Sample label: neg \n",
            "\n",
            "Sample text: ['I', 'live', 'in', 'Salt', 'Lake', 'City', 'and', \"I'm\", 'not', 'a', 'Mormon', ',', 'so', 'why', 'did', 'I', 'rent', 'this', 'movie', '?', 'Well', 'because', 'I', 'live', 'in', 'Utah', 'and', 'thought', \"it'd\", 'be', 'nice', 'to', 'see', 'locations', 'I', 'know', 'in', 'a', 'film', '.', 'I', 'really', 'knew', 'going', 'into', 'it', 'that', 'I', \"wasn't\", 'going', 'to', 'get', 'the', 'inside', 'jokes', 'so', 'I', \"wasn't\", 'surprised', 'when', 'I', 'sat', 'with', 'the', 'deer', 'in', 'the', 'headlights', 'stare', '.', 'What', 'I', 'was', 'surprised', 'at', 'was', 'the', 'ant-non', 'Mormon', 'actions', 'that', 'were', 'placed', 'in', 'this', 'film.<br', '/><br', '/>I', 'know', \"it's\", 'a', 'Mormon', 'film', ',', 'catered', 'to', 'the', 'members', 'of', 'the', 'LDS', 'Church', ',', 'but', 'I', 'found', 'it', 'offensive', 'because', 'of', 'the', 'typical', 'stereotype', 'of', 'people', 'that', \"isn't\", 'of', 'their', 'faith', '.', 'Every', 'non', 'Mormon', ',', 'which', \"wasn't\", 'many', ',', 'drank', ',', 'smoked', 'and', 'had', 'an', 'amazing', 'selfishness', 'attitude', ',', 'why?<br', '/><br', '/>That', 'really', 'ticked', 'me', 'off', 'about', 'this', 'film', ',', 'they', 'made', 'the', 'Mormons', 'so', 'pure', ',', 'yet', 'the', 'rest', 'of', 'the', 'state', 'of', 'Utah', 'I', 'guess', 'is', 'filled', 'with', 'punk', 'psychos', 'just', 'because', 'they', \"don't\", 'follow', 'the', 'scriptures', 'of', 'the', 'LDS', 'Church.<br', '/><br', '/>I', 'can', 'understand', 'having', 'the', 'plots', 'revolve', 'around', 'all', 'LDS', 'members', ',', 'but', \"you'd\", 'think', 'Salt', 'Lake', 'City', 'was', '100%', 'Mormon', ',', 'which', \"isn't\", 'even', 'close', 'to', 'being', 'the', 'truth', '.', 'And', 'as', 'I', 'said', ',', 'the', 'non', 'Mormons', 'in', 'the', 'movie', 'were', 'portrayed', 'as', 'drunken', 'jerks', ',', 'please!<br', '/><br', '/>I', 'guess', 'I', 'just', \"don't\", 'get', 'it', 'because', 'I', \"don't\", 'belong', 'to', 'their', 'faith', 'and', 'I', 'guess', 'I', 'never', 'will', '.']\n",
            "Sample label: neg \n",
            "\n",
            "Sample text: ['This', 'is', 'exactly', 'the', 'type', 'of', 'film', 'that', 'frustrates', 'me', 'the', 'most', '.', 'Great', 'cast', ',', 'great', 'director', ',', 'great', 'story', 'potential', ',', 'then', 'they', 'ruin', 'it', 'all', 'with', 'a', 'screenplay', 'that', 'goes', 'nowhere...and', 'says', 'nothing', 'while', 'going', 'there', '!', 'There', 'is', 'no', 'depth', 'here', 'whatsoever', '.', 'No', 'depth', 'of', 'characters', ',', 'no', 'depth', 'of', 'plot', ',', 'no', 'depth', 'of', 'surprise', ',', 'suspense', ',', 'or', 'common', 'sense', '.', 'We', 'know', \"what's\", 'happening', ',', 'we', 'are', 'told', 'how', 'they', 'plan', 'to', 'fix', 'the', 'problem', ',', 'they', 'fix', 'the', 'problem', ',', 'throw', 'a', 'surprise', 'at', 'us', 'near', 'the', 'end', 'that', 'fails', 'to', 'generate', 'any', 'suspense', ',', 'then', 'they', 'end', 'the', 'film', 'abruptly', '.', 'Wasted', 'opportunity.<br', '/><br', '/>On', 'the', 'plus', 'side', ',', 'Glenn', 'Ford', 'leads', 'a', 'cast', 'of', 'UK', '(', 'and', 'one', 'French', ')', 'actors', 'who', 'are', 'all', 'fantastic', ',', 'doing', 'an', 'incredibly', 'impressive', 'job', 'with', 'the', 'one-dimensional', 'writing', 'they', 'were', 'given', '.', 'One', 'of', 'the', 'absolute', 'favorites', 'is', 'Herbert', 'Walton', 'as', '\"', 'Old', 'Charlie\"', ',', 'who', 'provides', 'some', 'wonderful', 'bits', 'of', 'humor', 'and', 'warmth', 'to', 'a', 'dark', 'and', 'serious', 'film', '.', 'I', 'also', 'thought', 'the', 'film', 'had', 'a', 'great', 'look', 'to', 'it...all', 'shadows', 'and', 'fog...very', 'film', 'noir', 'in', 'feel.<br', '/><br', '/>Even', 'though', 'the', 'actors', 'do', 'the', 'best', 'they', 'can', 'and', 'the', 'directing', 'is', 'enjoyable', ',', 'it', 'still', 'just', \"isn't\", 'enough', 'for', 'me', 'to', 'recommend', 'spending', 'the', 'time', 'to', 'view', 'the', 'film', '.', 'There', 'are', 'far', 'better', 'Glenn', 'Ford', 'movies', 'out', 'there', ':', 'The', 'Big', 'Heat', ',', 'Gilda', ',', 'Affair', 'in', 'Trinidad', ',', 'etc', '.']\n",
            "Sample label: neg \n",
            "\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "import torchtext\n",
        "import random\n",
        "\n",
        "def preprocess(review):\n",
        "    '''\n",
        "    Simple preprocessing function.\n",
        "    '''\n",
        "    res = []\n",
        "    for x in review.split(' '):\n",
        "        remove_beg=True if x[0] in {'(', '\"', \"'\"} else False\n",
        "        remove_end=True if x[-1] in {'.', ',', ';', ':', '?', '!', '\"', \"'\", ')'} else False\n",
        "        if remove_beg and remove_end: res += [x[0], x[1:-1], x[-1]]\n",
        "        elif remove_beg: res += [x[0], x[1:]]\n",
        "        elif remove_end: res += [x[:-1], x[-1]]\n",
        "        else: res += [x]\n",
        "    return res\n",
        "\n",
        "if __name__=='__main__':\n",
        "    train_data = torchtext.datasets.IMDB(root='.data', split='train')\n",
        "    train_data = list(train_data)\n",
        "    train_data = [(x[0], preprocess(x[1])) for x in train_data]\n",
        "    train_data, test_data = train_data[0:10000] + train_data[12500:12500+10000], train_data[10000:12500] + train_data[12500+10000:], \n",
        "\n",
        "    print('Num. Train Examples:', len(train_data))\n",
        "    print('Num. Test Examples:', len(test_data))\n",
        "\n",
        "    print(\"\\nSAMPLE DATA:\")\n",
        "    for x in random.sample(train_data, 5):\n",
        "        print('Sample text:', x[1])\n",
        "        print('Sample label:', x[0], '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kfg8RcyskyU"
      },
      "source": [
        "# Step 2: Create Dataloader [20 points]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvFX-iX5oq7T"
      },
      "source": [
        "## <font color='red'>TODO:</font> Define the Dataset Class [20 Points]\n",
        "\n",
        "In the following cell, we will define the <b>dataset</b> class. The dataset contains the tokenized data for your model. You need to implement the following functions: \n",
        "\n",
        "*   <b>` build_dictionary(self)`:</b>  <b>[10 points]</b> Creates the dictionaries `idx2word` and `word2idx`. You will represent each word in the dataset with a unique index, and keep track of this in these dictionaries. Use the hyperparameter `threshold` to control which words appear in the dictionary: a training word’s frequency should be `>= threshold` to be included in the dictionary.\n",
        "\n",
        "* <b>`convert_text(self)`:</b> Converts each review in the dataset to a list of indices, given by your `word2idx` dictionary. You should store this in the `textual_ids` variable, and the function does not return anything. If a word is not present in the  `word2idx` dictionary, you should use the `<UNK>` token for that word. Be sure to append the `<END>` token to the end of each review.\n",
        "\n",
        "*   <b>` get_text(self, idx) `:</b> Return the review at `idx` in the dataset as an array of indices corresponding to the words in the review. If the length of the review is less than `max_len`, you should pad the review with the `<PAD>` character up to the length of `max_len`. If the length is greater than `max_len`, then it should only return the first `max_len` words. The return type should be `torch.LongTensor`.\n",
        "\n",
        "*   <b>`get_label(self, idx) `</b>: Return the value `1` if the label for `idx` in the dataset is `positive`, and should return `0` if it is `negative`. The return type should be `torch.LongTensor`.\n",
        "\n",
        "*  <b> ` __len__(self) `:</b> Return the total number of reviews in the dataset as an `int`.\n",
        "\n",
        "*   <b>` __getitem__(self, idx)`:</b> <b>[10 points]</b> Return the (padded) text, and the label. The return type for both these items should be `torch.LongTensor`. You should use the ` get_label(self, idx) ` and ` get_text(self, idx) ` functions here.\n",
        "\n",
        "\n",
        "<b>Note:</b> You should convert all words to lower case in your functions.\n",
        "\n",
        "<font color='green'><b>Hint:</b> Make sure that you use instance variables such as `self.threshold` throughout your code, rather than the global variable `THRESHOLD` (defined later on). The variable `THRESHOLD` will not be known to the autograder, and the use of it within the class will cause an autograder error.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1irMn3LX2YDB"
      },
      "outputs": [],
      "source": [
        "PAD = '<PAD>'\n",
        "END = '<END>'\n",
        "UNK = '<UNK>'\n",
        "\n",
        "from torch.utils import data\n",
        "from collections import defaultdict\n",
        "\n",
        "class TextDataset(data.Dataset):\n",
        "    def __init__(self, examples, split, threshold, max_len, idx2word=None, word2idx=None):\n",
        "        ### DO NOT EDIT ###\n",
        "        \n",
        "        self.examples = examples\n",
        "        assert split in {'train', 'val', 'test'}\n",
        "        self.split = split\n",
        "        self.threshold = threshold\n",
        "        self.max_len = max_len\n",
        "\n",
        "        # Dictionaries\n",
        "        self.idx2word = idx2word\n",
        "        self.word2idx = word2idx\n",
        "        if split == 'train':\n",
        "            self.build_dictionary()\n",
        "        self.vocab_size = len(self.word2idx)\n",
        "        \n",
        "        # Convert text to indices\n",
        "        self.textual_ids = []\n",
        "        self.convert_text()\n",
        "\n",
        "    \n",
        "    def build_dictionary(self): \n",
        "        '''\n",
        "        Build the dictionaries idx2word and word2idx. This is only called when split='train', as these\n",
        "        dictionaries are passed in to the __init__(...) function otherwise. Be sure to use self.threshold\n",
        "        to control which words are assigned indices in the dictionaries.\n",
        "        Returns nothing.\n",
        "        '''\n",
        "        assert self.split == 'train'\n",
        "        \n",
        "        # Don't change this\n",
        "        self.idx2word = {0:PAD, 1:END, 2: UNK}\n",
        "        self.word2idx = {PAD:0, END:1, UNK: 2}\n",
        "\n",
        "        ##### TODO #####\n",
        "        # Count the frequencies of all words in the training data (self.examples)\n",
        "        # Assign idx (starting from 3) to all words having word_freq >= self.threshold\n",
        "        # Make sure you call word.lower() on each word to convert it to lowercase\n",
        "        temp = dict()\n",
        "        #print(self.examples)\n",
        "        for example in self.examples:\n",
        "          example = example[1]\n",
        "          for word in example:\n",
        "            word = word.lower()\n",
        "            temp[word] = temp.get(word, 0) + 1\n",
        "        idx = 3\n",
        "        for word, count_ in temp.items():\n",
        "          if count_ >= self.threshold:\n",
        "            self.idx2word[idx] = word\n",
        "            self.word2idx[word] = idx\n",
        "            idx += 1\n",
        "\n",
        "    def convert_text(self):\n",
        "        '''\n",
        "        Convert each review in the dataset (self.examples) to a list of indices, given by self.word2idx.\n",
        "        Store this in self.textual_ids; returns nothing.\n",
        "        '''\n",
        "        for example in self.examples:\n",
        "          example = example[1]\n",
        "          temp_list = []\n",
        "          for i, word in enumerate(example):\n",
        "            if word not in self.word2idx:\n",
        "              temp_list.append(self.word2idx[UNK])\n",
        "            else:\n",
        "              temp_list.append(self.word2idx[word])\n",
        "          temp_list.append(self.word2idx[END])\n",
        "          self.textual_ids.append(temp_list)\n",
        "        ##### TODO #####\n",
        "        # Remember to replace a word with the <UNK> token if it does not exist in the word2idx dictionary.\n",
        "        # Remember to append the <END> token to the end of each review.\n",
        "\n",
        "    def get_text(self, idx):\n",
        "        '''\n",
        "        Return the review at idx as a long tensor (torch.LongTensor) of integers corresponding to the words in the review.\n",
        "        You may need to pad as necessary (see above).\n",
        "        '''\n",
        "        ##### TODO #####\n",
        "        text_at_idx = self.textual_ids[idx]\n",
        "        if len(text_at_idx) >= self.max_len:\n",
        "          text_at_idx = text_at_idx[:self.max_len]\n",
        "        else:\n",
        "          number_of_pads = self.max_len - len(text_at_idx) \n",
        "          for _ in range(number_of_pads):\n",
        "            text_at_idx.append(self.word2idx[PAD])\n",
        "        return torch.LongTensor(text_at_idx)\n",
        "    \n",
        "    def get_label(self, idx):\n",
        "        '''\n",
        "        This function should return the value 1 if the label for idx in the dataset is 'positive', \n",
        "        and 0 if it is 'negative'. The return type should be torch.LongTensor.\n",
        "        '''\n",
        "        ##### TODO #####\n",
        "        label = self.examples[idx][0]\n",
        "        if label == 'pos':\n",
        "          return torch.tensor(1)\n",
        "        else:\n",
        "          return torch.tensor(0)\n",
        "\n",
        "    def __len__(self):\n",
        "        '''\n",
        "        Return the number of reviews (int value) in the dataset\n",
        "        '''\n",
        "        ##### TODO #####\n",
        "        return len(self.examples)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "        Return the review, and label of the review specified by idx.\n",
        "        '''\n",
        "        ##### TODO #####\n",
        "        return self.get_text(idx), self.get_label(idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxVxiGGbFJAj"
      },
      "source": [
        "##Sanity Check: Dataset Class\n",
        "\n",
        "The code below runs a sanity check for your `Dataset` class. The tests are similar to the hidden ones in Gradescope. However, note that passing the sanity check does <b>not</b> guarantee that you will pass the autograder; it is intended to help you debug."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvHIZt8Z-RzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9789013-782e-4dbe-a54a-4ec7da873e6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample dataset:\n",
            "('pos', ['Your', 'life', 'is', 'good', 'when', 'you', 'have', 'money', ',', 'success', 'and', 'health'])\n",
            "('neg', ['Life', 'is', 'bad', 'when', 'you', 'got', 'not', 'a', 'lot'])\n",
            "\n",
            "--- TEST: idx2word and word2idx dictionaries ---\n",
            "\tthreshold: 1 \tmax_len: 3 \tPASSED \t\n",
            "\tthreshold: 2 \tmax_len: 3 \tPASSED \t\n",
            "\tthreshold: 3 \tmax_len: 3 \tPASSED \t\n",
            "\n",
            "--- TEST: len(dataset) ---\n",
            "\tPASSED\n",
            "\n",
            "--- TEST: __getitem__(self, idx) ---\n",
            "\tthreshold: 1 \tmax_len: 3 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 1 \tmax_len: 3 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 1 \tmax_len: 8 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 1 \tmax_len: 8 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 1 \tmax_len: 15 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 1 \tmax_len: 15 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 2 \tmax_len: 3 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 2 \tmax_len: 3 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 2 \tmax_len: 8 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 2 \tmax_len: 8 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 2 \tmax_len: 15 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 2 \tmax_len: 15 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 3 \tmax_len: 3 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 3 \tmax_len: 3 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 3 \tmax_len: 8 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 3 \tmax_len: 8 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 3 \tmax_len: 15 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 3 \tmax_len: 15 \tidx: 1 \tPASSED \t\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "def sanityCheckDataSet():\n",
        "    #\tRead in the sample corpus\n",
        "    reviews = [('pos', 'Your life is good when you have money, success and health'),\n",
        "               ('neg', 'Life is bad when you got not a lot')]\n",
        "    data = [(x[0], preprocess(x[1])) for x in reviews]\n",
        "    print(\"Sample dataset:\")\n",
        "    for x in data: print(x)\n",
        "\n",
        "    thresholds = [1,2,3]\n",
        "    print('\\n--- TEST: idx2word and word2idx dictionaries ---') # max_len does not matter for this test\n",
        "    correct = [[',', '<END>', '<PAD>', '<UNK>', 'a', 'and', 'bad', 'good', 'got', 'have', 'health', 'is', 'life', 'lot', 'money', 'not', 'success', 'when', 'you', 'your'], ['<END>', '<PAD>', '<UNK>', 'is', 'life', 'when', 'you'], ['<END>', '<PAD>', '<UNK>']]\n",
        "    for i in range(len(thresholds)):\n",
        "        dataset = TextDataset(data, 'train', threshold=thresholds[i], max_len=3)\n",
        "\n",
        "        has_passed, message = True, ''\n",
        "        if has_passed and (dataset.vocab_size != len(dataset.word2idx) or dataset.vocab_size != len(dataset.idx2word)):\n",
        "            has_passed, message = False, 'dataset.vocab_size (' + str(dataset.vocab_size) + ') must be the same length as dataset.word2idx (' + str(len(dataset.word2idx)) + ') and dataset.idx2word ('+str(len(dataset.idx2word)) +').'\n",
        "        if has_passed and (dataset.vocab_size != len(correct[i])):\n",
        "            has_passed, message = False, 'Your vocab size is incorrect. Expected: ' + str(len(correct[i])) + '\\tGot: ' + str(dataset.vocab_size)\n",
        "        if has_passed and sorted(list(dataset.idx2word.keys())) != list(range(0, dataset.vocab_size)):\n",
        "            has_passed, message = False, 'dataset.idx2word must have keys ranging from 0 to dataset.vocab_size-1. Keys in your dataset.idx2word: ' + str(sorted(list(dataset.idx2word.keys())))\n",
        "        if has_passed and sorted(list(dataset.word2idx.keys())) != correct[i]:\n",
        "            has_passed, message = False, 'Your dataset.word2idx has incorrect keys. Expected: ' + str(correct[i]) + '\\tGot: ' + str(sorted(list(dataset.word2idx.keys())))\n",
        "        if has_passed: # Check that word2idx and idx2word are consistent\n",
        "            widx = sorted(list(dataset.word2idx.items())) \n",
        "            idxw = sorted(list([(v,k) for k,v in dataset.idx2word.items()]))\n",
        "            if not (len(widx) == len(idxw) and all([widx[q] == idxw[q] for q in range(len(widx))])):\n",
        "                has_passed, message = False, 'Your dataset.word2idx and dataset.idx2word are not consistent. dataset.idx2word: ' + str(dataset.idx2word) + '\\tdataset.word2idx: ' + str(dataset.word2idx)\n",
        "\n",
        "        status = 'PASSED' if has_passed else 'FAILED'\n",
        "        print('\\tthreshold:', thresholds[i], '\\tmax_len:', 3, '\\t'+status, '\\t'+message)\n",
        "    \n",
        "    print('\\n--- TEST: len(dataset) ---')\n",
        "    has_passed = len(dataset) == 2\n",
        "    if has_passed: print('\\tPASSED')\n",
        "    else: print('\\tlen(dataset) is incorrect. Expected: 2\\tGot: ' + str(len(dataset)))\n",
        "\n",
        "    print('\\n--- TEST: __getitem__(self, idx) ---')\n",
        "    max_lens = [3,8,15]\n",
        "    idxes = [0,1]\n",
        "    combos = [{'threshold': t, 'max_len': m, 'idx': idx} for t in thresholds for m in max_lens for idx in idxes]\n",
        "    correct = [(torch.tensor([3, 4, 5]), torch.tensor(1)), (torch.tensor([ 4,  5, 15]), torch.tensor(0)), (torch.tensor([ 3,  4,  5,  6,  7,  8,  9, 10]), torch.tensor(1)), (torch.tensor([ 4,  5, 15,  7,  8, 16, 17, 18]), torch.tensor(0)), (torch.tensor([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  1,  0,  0]), torch.tensor(1)), (torch.tensor([ 4,  5, 15,  7,  8, 16, 17, 18, 19,  1,  0,  0,  0,  0,  0]), torch.tensor(0)), (torch.tensor([2, 3, 4]), torch.tensor(1)), (torch.tensor([3, 4, 2]), torch.tensor(0)), (torch.tensor([2, 3, 4, 2, 5, 6, 2, 2]), torch.tensor(1)), (torch.tensor([3, 4, 2, 5, 6, 2, 2, 2]), torch.tensor(0)), (torch.tensor([2, 3, 4, 2, 5, 6, 2, 2, 2, 2, 2, 2, 1, 0, 0]), torch.tensor(1)), (torch.tensor([3, 4, 2, 5, 6, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0]), torch.tensor(0)), (torch.tensor([2, 2, 2]), torch.tensor(1)), (torch.tensor([2, 2, 2]), torch.tensor(0)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2]), torch.tensor(1)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2]), torch.tensor(0)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0]), torch.tensor(1)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0]), torch.tensor(0))]\n",
        "    for i in range(len(combos)):\n",
        "        combo = combos[i]\n",
        "        dataset = TextDataset(data, 'train', threshold=combo['threshold'], max_len=combo['max_len'])\n",
        "        returned = dataset.__getitem__(combo['idx'])\n",
        "\n",
        "        has_passed, message = True, ''\n",
        "        if has_passed and len(returned) != 2:\n",
        "            has_passed, message = False, 'dataset.__getitem__(idx) must return 2 things. Got ' + str(len(returned)) +' things instead.'\n",
        "        if has_passed and (type(returned[0]) != torch.Tensor or type(returned[1]) != torch.Tensor):\n",
        "            has_passed, message = False, 'Both returns must be of type torch.Tensor. Got: (' + str(type(returned[0])) + ', ' + str(type(returned[1])) + ')'\n",
        "        if has_passed and (returned[0].shape != correct[i][0].shape):\n",
        "            has_passed, message = False, 'Shape of first return is incorrect. Expected: ' + str(correct[i][0].shape) + '.\\tGot: ' + str(returned[0].shape)\n",
        "        if has_passed and (returned[1].shape != correct[i][1].shape):\n",
        "            has_passed, message = False, 'Shape of second return is incorrect. Expected: ' + str(correct[i][1].shape) + '.\\tGot: ' + str(returned[1].shape) + '\\n\\t\\tHint: torch.Size([]) means that the tensor should be dimensionless (just a number). Try squeezing your result.'\n",
        "        if has_passed and (returned[1] != correct[i][1]):\n",
        "            has_passed, message = False, 'Label (second return) is incorrect. Expected: ' + str(correct[i][1]) + '.\\tGot: ' + str(returned[1])\n",
        "        if has_passed:\n",
        "            correct_padding_idxes, your_padding_idxes = torch.where(correct[i][0] == 0)[0], torch.where(returned[0] == dataset.word2idx[PAD])[0]\n",
        "            if not (correct_padding_idxes.shape == your_padding_idxes.shape and torch.all(correct_padding_idxes == your_padding_idxes)):\n",
        "                has_passed, message = False, 'Padding is not correct. Expected padding indxes: ' + str(correct_padding_idxes) + '.\\tYour padding indexes: ' + str(your_padding_idxes)\n",
        "\n",
        "        status = 'PASSED' if has_passed else 'FAILED'\n",
        "        print('\\tthreshold:', combo['threshold'], '\\tmax_len:', combo['max_len'] , '\\tidx:', combo['idx'], '\\t'+status, '\\t'+message)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    sanityCheckDataSet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR4VQbQCNZH6"
      },
      "source": [
        "The following cell builds the dataset on the IMDb movie reviews and prints an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSxpGXj6ml9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31da2d25-9770-44cd-c3d1-86c31ad96977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 19002 \n",
            "\n",
            "Example text:\n",
            "['Is', 'there', 'any', 'other', 'time', 'period', 'that', 'has', 'been', 'so', 'exhaustively', 'covered', 'by', 'television', '(', 'or', 'the', 'media', 'in', 'general', ')', 'as', 'the', '1960s', '?', 'No', '.', 'And', 'do', 'we', 'really', 'need', 'yet', 'another', 'trip', 'through', 'that', 'turbulent', 'time', '?', 'Not', 'really', '.', 'But', 'if', 'we', 'must', 'have', 'one', ',', 'does', 'it', 'have', 'to', 'be', 'as', 'shallow', 'as', '\"', 'The', \"'\", '60s\"', '?', '<br', '/><br', '/>I', 'like', 'to', 'think', 'that', 'co-writers', 'Bill', 'Couturie', 'and', 'Robert', 'Greenfield', 'had', 'more', 'in', 'mind', 'for', 'this', 'two-part', 'miniseries', 'than', 'what', 'ultimately', 'resulted', ',', 'especially', 'given', \"Couturie's\", 'involvement', 'in', 'the', 'superb', 'HBO', 'movie', '\"', 'Dear', 'America', ':', 'Letters', 'Home', 'From', 'Vietnam', '\"', 'which', 'utilized', 'little', 'original', 'music', 'and', 'no', 'original', 'footage', ',', 'letting', 'the', 'sights', 'and', 'sounds', 'of', 'the', 'time', 'speak', 'for', 'themselves', '.', 'This', 'presentation', 'intercuts', 'file', 'footage', 'with', 'the', 'dramatic', 'production', ',', 'but', 'it', \"doesn't\", 'do', 'anyone', 'any', 'favours', 'by', 'trying', 'to', 'do', 'too', 'much', 'in', 'too', 'little', 'time', ';', 'like', 'so', 'many', 'of', 'its', 'ilk', ',', \"it's\", 'seen', 'from', 'the', 'point', 'of', 'view', 'of', 'one', 'family', '.', 'But', 'the', 'children', 'of', 'the', 'family', 'seem', 'to', 'be', 'involved', 'tangentially', 'with', 'almost', 'every', 'major', 'event', 'of', 'the', \"'\", '60s', '(', \"it's\", 'amazing', 'that', 'one', 'of', 'them', \"doesn't\", 'go', 'to', 'the', 'Rolling', 'Stones', 'gig', 'at', 'Altamont)', ',', 'making', 'it', 'seem', 'less', 'like', 'a', 'period', 'drama', 'and', 'more', 'like', 'a', 'Cliff', 'Notes', 'version', 'of', 'the', 'decade.<br', '/><br', '/>The', 'makers', 'rush', 'through', 'it', 'so', 'much', 'that', \"there's\", 'little', 'or', 'no', 'time', 'to', 'give', 'the', 'characters', 'any', 'character', ',', 'with', 'the', 'stick', 'figures', 'called', 'our', 'protagonists', 'off', 'screen', 'for', 'ages', 'at', 'a', 'time', '-', 'the', \"children's\", 'father', 'is', 'especially', 'clichéd', '-', 'and', 'then', 'when', \"they're\", 'back', 'on', 'BLAMMO', '!', \"it's\", 'something', 'else', '.', 'Garry', 'Trudeau', 'could', 'teach', 'the', 'filmmakers', 'a', 'thing', 'or', 'two', 'about', 'doing', 'this', 'kind', 'of', 'thing', 'properly', '.', 'In', 'fairness', ',', 'Jerry', \"O'Connell\", ',', 'Jordana', 'Brewster', ',', 'Jeremy', 'Sisto', ',', 'Julia', 'Stiles', 'and', 'Charles', 'S', '.', 'Dutton', 'give', 'their', 'material', 'the', 'old', 'college', 'try', ',', 'but', \"they're\", 'wasted', '(', 'especially', 'the', 'latter', 'two)', ';', \"it's\", 'undeniably', 'good', 'to', 'see', 'David', 'Alan', 'Grier', 'in', 'a', 'rare', 'straight', 'role', 'as', 'activist', 'Fred', 'Hampton', ',', 'and', 'Rosanna', 'Arquette', '(', 'in', 'an', 'uncredited', 'cameo', 'in', 'part', '2', ')', 'is', 'always', 'welcome.<br', '/><br', '/>What', \"isn't\", 'welcome', 'is', 'how', '\"', 'The', \"'\", '60s', '\"', 'drowns', 'the', 'soundtrack', 'with', 'so', 'many', 'period', 'songs', 'that', 'it', 'ultimately', 'reduces', 'its', 'already', 'minimal', 'effect', '(', 'and', 'this', 'may', 'well', 'be', 'the', 'only', 'time', 'an', 'American', 'TV', 'presentation', 'about', 'post-60s', 'America', 'never', 'mentions', 'the', 'British', 'Invasion', '-', 'no', 'Beatles', ',', 'no', 'Rolling', 'Stones..', '.', 'then', 'again', ',', \"there's\", 'only', 'so', 'much', 'tunes', 'you', 'can', 'shoehorn', 'into', 'a', 'soundtrack', 'album', ',', 'right?)', '.', 'Capping', 'its', 'surface-skimming', 'approach', 'to', 'both', 'the', 'time', 'and', 'the', 'plot', 'with', 'an', 'almost', 'out-of-place', 'happy', 'ending', ',', '\"', 'American', 'Dreams', '\"', 'and', '\"', 'The', 'Wonder', 'Years', '\"', 'did', 'it', 'all', 'much', ',', 'much', 'better', '.', 'Nothing', 'to', 'see', 'here', 'you', \"can't\", 'see', 'elsewhere', ',', 'people..', '.', 'except', 'for', 'Julia', 'Stiles', 'doing', 'the', 'twist', ',', 'that', 'is', '.']\n",
            "tensor([    2,   258,   155,   528,   323,  1162,    15,   103,   356,   302,\n",
            "            2,  2173,    28,   890,   175,   245,    13,  2860,    22,   918,\n",
            "          179,    88,    13,  7974,   215,     2,    24,     2,   151,   688,\n",
            "           47,  1674,  1937,  1087,  2225,   963,    15, 13066,   323,   215,\n",
            "            2,    47,    24,     2,    31,   688,   458,   182,   253,    38,\n",
            "          305,    17,   182,    34,   167,    88,   986,    88,    45,     2,\n",
            "          610,     2,   215,  1328,    52,     2,   127,    34,   376,    15,\n",
            "            2,     2,     2,    91,     2,     2,    48,   743,    22,   132,\n",
            "           50,    36,     2,  9119,   161,    81,  3517,  8292,    38,   511,\n",
            "          848,     2,  8831,    22,    13,  5584,     2,   369,    45,     2,\n",
            "            2,   185,     2,     2,     2,     2,    45,   232,  6281,  1130,\n",
            "         1269,  1581,    91,   176,  1269,  3583,    38,  1703,    13, 14670,\n",
            "           91,   791,    11,    13,   323,  1722,    50,   529,    24,     2,\n",
            "         3113,     2,  7225,  3583,   105,    13,  4253,  2305,    38,   180,\n",
            "           17,   181,   151,   170,   155, 15936,    28,  1360,    34,   151])\n",
            "\n",
            "Example label:\n",
            "neg\n",
            "tensor(0)\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "if __name__=='__main__':\n",
        "    train_dataset = TextDataset(train_data, 'train', threshold=10, max_len=150)\n",
        "    print('Vocab size:', train_dataset.vocab_size, '\\n')\n",
        "\n",
        "    randidx = random.randint(0, len(train_dataset)-1)\n",
        "    text, label = train_dataset[randidx]\n",
        "    print('Example text:')\n",
        "    print(train_data[randidx][1])\n",
        "    print(text)\n",
        "    print('\\nExample label:')\n",
        "    print(train_data[randidx][0])\n",
        "    print(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_4FFhulaAod"
      },
      "source": [
        "# Step 3: Train a Convolutional Neural Network (CNN) [40 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcSKydlClwOC"
      },
      "source": [
        "## <font color='red'>TODO:</font> Define the CNN Model [20 points]\n",
        "Here you will define your convolutional neural network for text classification. We provide you with the CNN class, you need to fill in parts of the `__init__(...)` and `forward(...)` functions. Each of these functions is worth 10 points.\n",
        "\n",
        "We have provided you with instructions and hints in the comments. In particular, pay attention to the desired shapes; you may find it helpful to print the shape of the tensors as you code. It may also help to keep PyTorch documentation open for the modules & functions you are using, since they describe input and output dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ztuy2hUaAof"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, out_channels, filter_heights, stride, dropout, num_classes, pad_idx):\n",
        "        super(CNN, self).__init__()\n",
        "        \n",
        "        ##### TODO #####\n",
        "        # Create an embedding layer (https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
        "        #   to represent the words in your vocabulary. Make sure to use vocab_size, embed_size, and pad_idx here.\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size, pad_idx)\n",
        "\n",
        "        # Define multiple Convolution layers (nn.Conv2d) with filter (kernel) size [filter_height, embed_size] based on your \n",
        "        #   different filter_heights.\n",
        "        self.conv = []\n",
        "        for height in filter_heights:\n",
        "          self.conv.append(nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size= (height,embed_size), stride=stride))\n",
        "        # Input channels will be 1 and output channels will be out_channels (these many different filters will be trained \n",
        "        #   for each convolution layer)\n",
        "        # If you want, you can store a list of modules inside nn.ModuleList.\n",
        "        # Note: even though your conv layers are nn.Conv2d, we are doing a 1d convolution since we are only moving the filter \n",
        "        #   in one direction\n",
        "        self.conv = nn.ModuleList(self.conv)\n",
        "        # Create a dropout layer (nn.Dropout) using dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # Define a linear layer (nn.Linear) that consists of num_classes units \n",
        "        #   and takes as input the concatenated output for all cnn layers (out_channels * num_of_cnn_layers units)\n",
        "        self.linear = nn.Linear(in_features = out_channels * len(filter_heights), out_features = num_classes)\n",
        "\n",
        "    def forward(self, texts):\n",
        "        \"\"\"\n",
        "        texts: LongTensor [batch_size, max_len]\n",
        "        \n",
        "        Returns output: Tensor [batch_size, num_classes]\n",
        "        \"\"\"\n",
        "        ##### TODO #####\n",
        "\n",
        "        # Pass texts through your embedding layer to convert from word ids to word embeddings\n",
        "        #   Resulting: shape: [batch_size, max_len, embed_size]\n",
        "\n",
        "        # Input to conv should have 1 channel. Take a look at torch's unsqueeze() function\n",
        "        #   Resulting shape: [batch_size, 1, MAX_LEN, embed_size]\n",
        "        word_embeddings = self.embedding(texts).unsqueeze(1)\n",
        "        # Pass these texts to each of your conv layers and compute their output as follows:\n",
        "        #   Your cnn output will have shape [batch_size, out_channels, *, 1] where * depends on filter_height and stride\n",
        "        #   Convert to shape [batch_size, out_channels, *] (see torch's squeeze() function)\n",
        "        #   Apply non-linearity on it (F.relu() is a commonly used one. Feel free to try others)\n",
        "        #   Take the max value across last dimension to have shape [batch_size, out_channels]\n",
        "        # Concatenate (torch.cat) outputs from all your cnns [batch_size, (out_channels*num_of_cnn_layers)]\n",
        "        #\n",
        "        convolutions, max_values = [], []\n",
        "        for conv in self.conv:\n",
        "          new_conv = F.relu(conv(word_embeddings).squeeze(3))\n",
        "          convolutions.append(new_conv)\n",
        "        for conv in convolutions:\n",
        "          new_max = F.max_pool1d(conv, conv.shape[2]).squeeze(2)\n",
        "          max_values.append(new_max)\n",
        "        concatenate = torch.cat(max_values, dim = 1)\n",
        "        drop_out = self.dropout(concatenate)\n",
        "        return self.linear(drop_out)\n",
        "        # Let's understand what you just did:\n",
        "        #   Since each cnn is of different filter_height, it will look at different number of words at a time\n",
        "        #     So, a filter_height of 3 means your cnn looks at 3 words (3-grams) at a time and tries to extract some information from it\n",
        "        #   Each cnn will learn out_channels number of features from the words it sees at a time\n",
        "        #   Then you applied a non-linearity and took the max value for all channels\n",
        "        #     You are essentially trying to find important n-grams from the entire text\n",
        "        # Everything happens on a batch simultaneously hence you have that additional batch_size as the first dimension\n",
        "\n",
        "        # Apply dropout\n",
        "\n",
        "        # Pass your output through the linear layer and return its output \n",
        "        #   Resulting shape: [batch_size, num_classes]\n",
        "\n",
        "        ##### NOTE: Do not apply a sigmoid or softmax to the final output - done in training method!\n",
        "\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mVE_ujfnh0w"
      },
      "source": [
        "##Sanity Check: CNN Model\n",
        "\n",
        "The code below runs a sanity check for your `CNN` class. The tests are similar to the hidden ones in Gradescope. However, note that passing the sanity check does <b>not</b> guarantee that you will pass the autograder; it is intended to help you debug."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yy9oF6qUUHvV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc3a8d1a-89d0-4782-a864-caf6e4ab489f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- TEST: Number of Model Parameters (tests __init__(...)) ---\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 22434\tYour Num. Params: 22434\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 22531\tYour Num. Params: 22531\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 22434\tYour Num. Params: 22434\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 22531\tYour Num. Params: 22531\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 23874\tYour Num. Params: 23874\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 23939\tYour Num. Params: 23939\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 23874\tYour Num. Params: 23874\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 23939\tYour Num. Params: 23939\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 41730\tYour Num. Params: 41730\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 42115\tYour Num. Params: 42115\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 41730\tYour Num. Params: 41730\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 42115\tYour Num. Params: 42115\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47490\tYour Num. Params: 47490\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47747\tYour Num. Params: 47747\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47490\tYour Num. Params: 47490\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47747\tYour Num. Params: 47747\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 44578\tYour Num. Params: 44578\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 44675\tYour Num. Params: 44675\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 44578\tYour Num. Params: 44578\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 44675\tYour Num. Params: 44675\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47554\tYour Num. Params: 47554\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47619\tYour Num. Params: 47619\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47554\tYour Num. Params: 47554\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47619\tYour Num. Params: 47619\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 82306\tYour Num. Params: 82306\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 82691\tYour Num. Params: 82691\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 82306\tYour Num. Params: 82306\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 82691\tYour Num. Params: 82691\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 94210\tYour Num. Params: 94210\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 94467\tYour Num. Params: 94467\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 94210\tYour Num. Params: 94210\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 94467\tYour Num. Params: 94467\n",
            "\n",
            "--- TEST: Output shape of forward(...) ---\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "count_parameters = lambda model: sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def sanityCheckModel(all_test_params, NN, expected_outputs, init_or_forward, data_loader):\n",
        "    print('--- TEST: ' + ('Number of Model Parameters (tests __init__(...))' if init_or_forward=='init' else 'Output shape of forward(...)') + ' ---')\n",
        "    \n",
        "    if init_or_forward == \"forward\":\n",
        "        # Reading the first batch of data for testing\n",
        "        for texts_, labels_ in data_loader:\n",
        "            texts_batch, labels_batch = texts_, labels_\n",
        "            break\n",
        "\n",
        "    for tp_idx, (test_params, expected_output) in enumerate(zip(all_test_params, expected_outputs)):       \n",
        "        if init_or_forward == \"forward\":\n",
        "            batch_size = test_params['batch_size']\n",
        "            texts = texts_batch[:batch_size]\n",
        "\n",
        "        # Construct the student model\n",
        "        tps = {k:v for k, v in test_params.items() if k != 'batch_size'}\n",
        "        stu_nn = NN(**tps)\n",
        "\n",
        "        if init_or_forward == \"forward\":\n",
        "            with torch.no_grad(): \n",
        "                stu_out = stu_nn(texts)\n",
        "            ref_out_shape = expected_output\n",
        "\n",
        "            has_passed = torch.is_tensor(stu_out)\n",
        "            if not has_passed: msg = 'Output must be a torch.Tensor; received ' + str(type(stu_out))\n",
        "            else: \n",
        "                has_passed = stu_out.shape == ref_out_shape\n",
        "                msg = 'Your Output Shape: ' + str(stu_out.shape)\n",
        "            \n",
        "\n",
        "            status = 'PASSED' if has_passed else 'FAILED'\n",
        "            message = '\\t' + status + \"\\t Init Input: \" + str({k:v for k,v in tps.items()}) + '\\tForward Input Shape: ' + str(texts.shape) + '\\tExpected Output Shape: ' + str(ref_out_shape) + '\\t' + msg\n",
        "            print(message)\n",
        "        else:\n",
        "            stu_num_params = count_parameters(stu_nn)\n",
        "            ref_num_params = expected_output\n",
        "            comparison_result = (stu_num_params == ref_num_params)\n",
        "\n",
        "            status = 'PASSED' if comparison_result else 'FAILED'\n",
        "            message = '\\t' + status + \"\\tInput: \" + str({k:v for k,v in test_params.items()}) + ('\\tExpected Num. Params: ' + str(ref_num_params) + '\\tYour Num. Params: '+ str(stu_num_params))\n",
        "            print(message)\n",
        "\n",
        "        del stu_nn\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Test init\n",
        "    inputs = [{'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}]\n",
        "    expected_outputs = [22434, 22531, 22434, 22531, 23874, 23939, 23874, 23939, 41730, 42115, 41730, 42115, 47490, 47747, 47490, 47747, 44578, 44675, 44578, 44675, 47554, 47619, 47554, 47619, 82306, 82691, 82306, 82691, 94210, 94467, 94210, 94467]\n",
        "\n",
        "    sanityCheckModel(inputs, CNN, expected_outputs, \"init\", None)\n",
        "    print()\n",
        "\n",
        "    # Test forward\n",
        "    inputs = [{'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}]\n",
        "    expected_outputs = [torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2])]\n",
        "    sanity_dataset = TextDataset(train_data, 'train', 5, 150)\n",
        "    sanity_loader = torch.utils.data.DataLoader(sanity_dataset, batch_size=50, shuffle=True, num_workers=2, drop_last=True)\n",
        "\n",
        "    sanityCheckModel(inputs, CNN, expected_outputs, \"forward\", sanity_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FupiBIfasCu_"
      },
      "source": [
        "## Train CNN Model\n",
        "\n",
        "First, we initialize the train and test <b>dataloaders</b>. A dataloader is responsible for providing batches of data to your model. Notice how we first instantiate datasets for the train and test data, and that we use the training vocabulary for both.\n",
        "\n",
        "You do not need to edit this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2QYl334n9ON"
      },
      "outputs": [],
      "source": [
        "if __name__=='__main__':\n",
        "    THRESHOLD = 5 # Don't change this\n",
        "    MAX_LEN = 200 # Don't change this\n",
        "    BATCH_SIZE = 32 # Feel free to try other batch sizes\n",
        "\n",
        "    train_dataset = TextDataset(train_data, 'train', THRESHOLD, MAX_LEN)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n",
        "\n",
        "    test_dataset = TextDataset(test_data, 'test', THRESHOLD, MAX_LEN, train_dataset.idx2word, train_dataset.word2idx)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=1, drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvsctopWmeoY"
      },
      "source": [
        "Now we provide you with a function that takes your model and trains it on the data.\n",
        "\n",
        "You do not need to edit this cell. However, you may want to write code to save your model periodically, as Colab connections are not permanent. See the tutorial here if you wish to do this: https://pytorch.org/tutorials/beginner/saving_loading_models.html."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LD-Jj2rUFOzr"
      },
      "outputs": [],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def train_model(model, num_epochs, data_loader, optimizer, criterion):\n",
        "    print('Training Model...')\n",
        "    model.train()\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        epoch_loss = 0\n",
        "        epoch_acc = 0\n",
        "        for texts, labels in data_loader:\n",
        "            texts = texts.to(DEVICE) # shape: [batch_size, MAX_LEN]\n",
        "            labels = labels.to(DEVICE) # shape: [batch_size]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(texts)\n",
        "            acc = accuracy(output, labels)\n",
        "            \n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        print('[TRAIN]\\t Epoch: {:2d}\\t Loss: {:.4f}\\t Train Accuracy: {:.2f}%'.format(epoch+1, epoch_loss/len(data_loader), 100*epoch_acc/len(data_loader)))\n",
        "    print('Model Trained!\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyIZS0WUhFA6"
      },
      "source": [
        "Here are some other helper functions we will need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVP2scuyhG5f"
      },
      "outputs": [],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "def accuracy(output, labels):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch\n",
        "    output: Tensor [batch_size, n_classes]\n",
        "    labels: LongTensor [batch_size]\n",
        "    \"\"\"\n",
        "    preds = output.argmax(dim=1) # find predicted class\n",
        "    correct = (preds == labels).sum().float() # convert into float for division \n",
        "    acc = correct / len(labels)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjvX5c6Isw9e"
      },
      "source": [
        "Now you can instantiate your model. We provide you with some recommended hyperparameters; you should be able to get the desired accuracy with these, but feel free to play around with them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5UtdjGDuBty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab9bfefb-7c61-4fe3-efa7-abf6963eebc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 3,879,746 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "if __name__=='__main__':\n",
        "    cnn_model = CNN(vocab_size = train_dataset.vocab_size, # Don't change this\n",
        "                embed_size = 128, \n",
        "                out_channels = 64, \n",
        "                filter_heights = [2, 3, 4], \n",
        "                stride = 1, \n",
        "                dropout = 0.5, \n",
        "                num_classes = 2, # Don't change this\n",
        "                pad_idx = train_dataset.word2idx[PAD]) # Don't change this\n",
        "\n",
        "    # Put your model on the device (cuda or cpu)\n",
        "    cnn_model = cnn_model.to(DEVICE)\n",
        "    \n",
        "    print('The model has {:,d} trainable parameters'.format(count_parameters(cnn_model)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeHpqw6zvkhI"
      },
      "source": [
        "Next, we create the **criterion**, which is our loss function: it is a measure of how well the model matches the empirical distribution of the data. We use cross-entropy loss (https://en.wikipedia.org/wiki/Cross_entropy).\n",
        "\n",
        "We also define the **optimizer**, which performs gradient descent. We use the Adam optimizer (https://arxiv.org/pdf/1412.6980.pdf), which has been shown to work well on these types of models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoeyQL4PoNoH"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "if __name__=='__main__':    \n",
        "    LEARNING_RATE = 5e-4 # Feel free to try other learning rates\n",
        "\n",
        "    # Define the loss function\n",
        "    criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "\n",
        "    # Define the optimizer\n",
        "    optimizer = optim.Adam(cnn_model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RopLfAJ9wOHN"
      },
      "source": [
        "Finally, we can train the model. If the model is implemented correctly and you're using the GPU, this cell should take around <b>4 minutes</b> (or less). Feel free to change the number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPOs1FifoNoN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275,
          "referenced_widgets": [
            "252361cf26b84811b14b97c875e3a054",
            "4b85b45f79664d73a2d66afcac3177d9",
            "7f5fdc04779b4e2d806593408aa10671",
            "acd0ff48aab640cc98225bbbd0870c2d",
            "25cedf7910404db5946ff5f475ac07d0",
            "376c9e791c5d4609a0d2b1919ceb25c4",
            "168e577de44e488792ccf6124b80656d",
            "f73120b205e24bf7a48acf614a58a5b8",
            "afdbf11060354eb09c26465ef5d6a404",
            "9166c0a7e9dd43caab4eefc8b71c3600",
            "5253448fe81f42ae84f5172d07e65557"
          ]
        },
        "outputId": "97e8c527-39b6-4865-9190-ba118c78c517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "252361cf26b84811b14b97c875e3a054"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]\t Epoch:  1\t Loss: 0.6704\t Train Accuracy: 61.51%\n",
            "[TRAIN]\t Epoch:  2\t Loss: 0.5486\t Train Accuracy: 71.68%\n",
            "[TRAIN]\t Epoch:  3\t Loss: 0.4909\t Train Accuracy: 75.89%\n",
            "[TRAIN]\t Epoch:  4\t Loss: 0.4484\t Train Accuracy: 78.64%\n",
            "[TRAIN]\t Epoch:  5\t Loss: 0.4074\t Train Accuracy: 81.83%\n",
            "[TRAIN]\t Epoch:  6\t Loss: 0.3700\t Train Accuracy: 83.42%\n",
            "[TRAIN]\t Epoch:  7\t Loss: 0.3308\t Train Accuracy: 85.58%\n",
            "[TRAIN]\t Epoch:  8\t Loss: 0.2937\t Train Accuracy: 87.75%\n",
            "[TRAIN]\t Epoch:  9\t Loss: 0.2612\t Train Accuracy: 89.10%\n",
            "[TRAIN]\t Epoch: 10\t Loss: 0.2277\t Train Accuracy: 90.73%\n",
            "Model Trained!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__=='__main__':    \n",
        "    N_EPOCHS = 10 # Feel free to change this\n",
        "    \n",
        "    # train model for N_EPOCHS epochs\n",
        "    train_model(cnn_model, N_EPOCHS, train_loader, optimizer, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-OJbZ72t6Yq"
      },
      "source": [
        "## Evaluate CNN Model [20 points]\n",
        "\n",
        "Now that we have trained a model for text classification, it is time to evaluate it. We have provided you with a function to do this; you do not need to modify anything.\n",
        "\n",
        "To pass the autograder for the CNN, you will need to achieve **82% accuracy** on the hidden test set on Gradescope. Note that the Gradescope test set is very similar, and the accuracies between the two datasets should be comparable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTiiYDZIF--7"
      },
      "outputs": [],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "import random\n",
        "\n",
        "def evaluate(model, data_loader, criterion, use_tqdm=False):\n",
        "    print('Evaluating performance on the test dataset...')\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    all_predictions = []\n",
        "    print(\"\\nSOME PREDICTIONS FROM THE MODEL:\")\n",
        "    iterator = tqdm(data_loader) if use_tqdm else data_loader\n",
        "    total = 0\n",
        "    for texts, labels in iterator:\n",
        "        bs = texts.shape[0]\n",
        "        total += bs\n",
        "        texts = texts.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        \n",
        "        output = model(texts)\n",
        "        acc = accuracy(output, labels) * len(labels)\n",
        "        pred = output.argmax(dim=1)\n",
        "        all_predictions.append(pred)\n",
        "        \n",
        "        loss = criterion(output, labels) * len(labels)\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "        if random.random() < 0.0015 and bs == 1:\n",
        "            print(\"Input: \"+' '.join([data_loader.dataset.idx2word[idx] for idx in texts[0].tolist() if idx not in {data_loader.dataset.word2idx[PAD], data_loader.dataset.word2idx[END]}]))\n",
        "            print(\"Prediction:\", pred.item(), '\\tCorrect Output:', labels.item(), '\\n')\n",
        "\n",
        "    full_acc = 100*epoch_acc/total\n",
        "    full_loss = epoch_loss/total\n",
        "    print('[TEST]\\t Loss: {:.4f}\\t Accuracy: {:.2f}%'.format(full_loss, full_acc))\n",
        "    predictions = torch.cat(all_predictions)\n",
        "    return predictions, full_acc, full_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z718w8e0oNoS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399,
          "referenced_widgets": [
            "6a11e8081abb4bfab3985cab31d7e6c6",
            "26631291ac2649a7b295d0f16b902920",
            "f2c354dc64a44e69a607b4f6314a41f6",
            "c0be46b9526643fca7896ae72ee11b54",
            "57c33af500ec4453b9fbc6f1274bab21",
            "c9370e6d571843448d49e601c178b452",
            "0359196e046a436a90b997351c7c0e23",
            "55e314c1f9034476afe2b23383943a15",
            "af430c9b0fc440eebacf64f5c18832bd",
            "0178870fca9249fbb40fa1902fc805e1",
            "aaa8eda3dc404b95b6efa0004453f95d"
          ]
        },
        "outputId": "6de9fa86-d21f-41bc-96c1-48a4bd7adf36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating performance on the test dataset...\n",
            "\n",
            "SOME PREDICTIONS FROM THE MODEL:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a11e8081abb4bfab3985cab31d7e6c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <UNK> domestic audiences <UNK> can see how they would applaud this movie . <UNK> outsiders , with no vested interests , it did not make much sense . <UNK> <UNK> were portrayed as <UNK> and the <UNK> as heroes . <UNK> supposedly romantic angle was superfluous and a distraction . <UNK> a young woman could ' love ' the lieutenant from just <UNK> him was nonsense . <UNK> she could , as mentioned at the end of the movie , never marry just because of this infatuation was beyond me . <UNK> mentioned the <UNK> were portrayed as idiots and that was <UNK> in the chase into the marsh . <UNK> hundred <UNK> troops advanced , pushing the <UNK> into the marsh . <UNK> the <UNK> hid and the <UNK> stopped at the edge of the marsh and just stood there listening . <UNK> suppose they did not want to get their boots wet , but <UNK> am sure an officer would have ordered 20 or 30 men into the water to search the marsh . <UNK> that would have ended the story . <UNK> , the <UNK> entered the barn where the <UNK> were hiding in the loft and\n",
            "Prediction: 0 \tCorrect Output: 0 \n",
            "\n",
            "Input: <UNK> ago <UNK> saw <UNK> <UNK> and it made a lasting impression on me , the atmosphere of the movie was first class , the acting memorable and the storyline a classic . <UNK> <UNK> bought the <UNK> and after watching <UNK> 1 again <UNK> looked eagerly to viewing <UNK> <UNK> . <UNK> was so pleased to realize early on into <UNK> 2 that here was a fitting follow on to the great <UNK> movie , again everything was just about perfect and <UNK> could not wait to see <UNK> <UNK> <UNK> . <UNK> , <UNK> wish <UNK> stopped at <UNK> . <UNK> storyline was not good , it seemed to me like a story made up just to have a story , the characters were weak especially the daughter . <UNK> <UNK> was a weak character that would have been eaten alive in <UNK> 1 or 2 . <UNK> scenes such as , <UNK> being invested with all the trappings of the <UNK> <UNK> with full choir , the assassin on horseback riding away into the sunset , the unseen helicopter machine gunning of the meeting ( where the ' goodies ' get away and everyone else is <UNK>\n",
            "Prediction: 0 \tCorrect Output: 0 \n",
            "\n",
            "Input: <UNK> had watched \" <UNK> <UNK> \" before <UNK> watched this one . <UNK> really liked \" <UNK> <UNK> , it was one of the best movies of the recent <UNK> <UNK> . <UNK> , <UNK> picked this \" <UNK> haunted \" because it was the same director , and it was kind of popular round here . <UNK> man , what a <UNK> . \" <UNK> haunted \" are three stories about love , revenge , ghosts , etc . that are no scary at all , not even disturbing ( as \" <UNK> eye \" <UNK> . no nothing . <UNK> can't even fill the 10 lines required for the <UNK> . <br /><br <UNK> boring.<br /><br <UNK> rate : 2/10\n",
            "Prediction: 0 \tCorrect Output: 0 \n",
            "\n",
            "Input: <UNK> to most other comments about \" <UNK> \" on the <UNK> <UNK> , <UNK> and my family found watching this film on <UNK> at home a complete waste of time and space.<br /><br <UNK> short , this was a film based on a script whose writer was being too clever by far . <UNK> than trying to tell a complex story in an intelligent and clear manner , it was assumed that constantly throwing mostly vague and hard to connect with each other <UNK> vignettes of different <UNK> from a dozen or so \" <UNK> \" at the audience made for great and clear viewing . <UNK> , sir , it does not . <UNK> does make for great viewing is total clarity , precision , plots and <UNK> - and characterisations - which have a beginning , a middle , and an end.<br /><br <UNK> kind of cinematic presentation - akin to the <UNK> <UNK> experience in a <UNK> restaurant - is pretentious and unintelligent in the <UNK> /><br <UNK> goodness , then , for the <UNK> and <UNK> <UNK> of the <UNK> and <UNK> film noirs of the 1940s and 1950s whose writers , director , and\n",
            "Prediction: 0 \tCorrect Output: 0 \n",
            "\n",
            "Input: <UNK> only watched the first series on <UNK> , but would <UNK> <UNK> <UNK> as a <UNK> plot with a <UNK> script . <UNK> series is as good as <UNK> and <UNK> , and almost as good as <UNK> <UNK> ( hence not a \" <UNK> , and far better than any of <UNK> <UNK> efforts . <UNK> there's plenty of action , some of it pretty bloody , the story is character driven . <UNK> some of the minor characters contribute to great story lines ; e.g . the <UNK> relationship ( or lack of ) with <UNK> and the <UNK> wife , and <UNK> and his dimwit friend ( who didn't last very long ( a <UNK> <UNK> <UNK> /><br <UNK> from the plot , the script and the acting , the other reasons <UNK> liked <UNK> /><br />1 . <UNK> made me want to visit <UNK> <UNK> and eat <UNK> with a <UNK> sauce . 2 . <UNK> music . 3 . <UNK> shows that literally anyone can suffer from mental health problems .\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "[TEST]\t Loss: 0.4016\t Accuracy: 82.74%\n"
          ]
        }
      ],
      "source": [
        "if __name__=='__main__':\n",
        "    evaluate(cnn_model, test_loader, criterion, use_tqdm=True) # Compute test data accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRCFvjwDthiA"
      },
      "source": [
        "# Step 4: Train a Recurrent Neural Network (RNN) [40 points]\n",
        "You will now build a text clasification model that is based on **recurrences**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-t8tlZviV2x"
      },
      "source": [
        "## <font color='red'>TODO:</font> Define the RNN Model [20 points]\n",
        "\n",
        "First, you will define the RNN. As with the CNN, we provide you with the skeleton of the class, and you need to fill in parts of the `__init__(...)` and `forward(...)` methods. Each of these functions is worth 10 points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nc_HxbP6klI"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, bidirectional, dropout, num_classes, pad_idx):\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        ##### TODO #####\n",
        "        self.bidirectional = bidirectional\n",
        "        # Create an embedding layer (https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
        "        #   to represent the words in your vocabulary. Make sure to use vocab_size, embed_size, and pad_idx here.\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size, pad_idx)\n",
        "        # Create a recurrent network (use nn.GRU, not nn.LSTM) with batch_first = True\n",
        "        # Make sure you use hidden_size, num_layers, dropout, and bidirectional here.\n",
        "        self.GRU = nn.GRU(embed_size, hidden_size, self.num_layers, batch_first=True, bidirectional=bidirectional)\n",
        "        # Create a dropout layer (nn.Dropout) using dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # Define a linear layer (nn.Linear) that consists of num_classes units \n",
        "        #   and takes as input the output of the last timestep. In the bidirectional case, you should concatenate\n",
        "        #   the output of the last timestep of the forward direction with the output of the last timestep of the backward direction).\n",
        "        size = hidden_size*2 if bidirectional else hidden_size\n",
        "        self.linear_layer = nn.Linear(size, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, texts):\n",
        "        \"\"\"\n",
        "        texts: LongTensor [batch_size, MAX_LEN]\n",
        "        \n",
        "        Returns output: Tensor [batch_size, num_classes]\n",
        "        \"\"\"\n",
        "        ##### TODO #####\n",
        "\n",
        "        # Pass texts through your embedding layer to convert from word ids to word embeddings\n",
        "        #   Resulting: shape: [batch_size, max_len, embed_size]\n",
        "        final_embedding = self.embedding(texts)\n",
        "        # Pass the result through your recurrent network\n",
        "        #   See PyTorch documentation for resulting shape for nn.GRU\n",
        "        output_state, hidden_state = self.GRU(final_embedding)\n",
        "        # Concatenate the outputs of the last timestep for each direction (see torch.cat(...))\n",
        "        #   This depends on whether or not your model is bidirectional.\n",
        "        #   Resulting shape: [batch_size, num_dirs*hidden_size]\n",
        "        \n",
        "        # Apply dropout\n",
        "        if self.bidirectional == True:\n",
        "          t = hidden_state.view(self.num_layers, 2, texts.size(0), self.hidden_size)\n",
        "          final = torch.cat((t[-1][0], t[-1][1]), dim = 1)\n",
        "        else:\n",
        "          t = hidden_state.view(self.num_layers, 1, texts.size(0), self.hidden_size)\n",
        "          final = torch.cat((t[-1], ), dim = 1).squeeze(0)\n",
        "        \n",
        "        dropout = self.dropout(final)\n",
        "        return self.linear_layer(dropout)\n",
        "\n",
        "        # Pass your output through the linear layer and return its output \n",
        "        #   Resulting shape: [batch_size, num_classes]\n",
        "\n",
        "        ##### NOTE: Do not apply a sigmoid or softmax to the final output - done in training method!\n",
        "        \n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class RNN(nn.Module):\n",
        "#     def __init__(self, vocab_size, embed_size, hidden_size, num_layers, bidirectional, dropout, num_classes, pad_idx):\n",
        "#         super(RNN, self).__init__()\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.num_layers = num_layers\n",
        "        \n",
        "#         self.embed = nn.Embedding(vocab_size, embed_size, padding_idx = pad_idx)\n",
        "#         self.rnn = nn.GRU(input_size = embed_size, hidden_size = hidden_size, num_layers = num_layers, bidirectional = bidirectional, batch_first = True)\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "#         if bidirectional:\n",
        "#           self.linear = nn.Linear(hidden_size*2, num_classes)\n",
        "#         else:\n",
        "#           self.linear = nn.Linear(hidden_size, num_classes)\n",
        "#         self.bidirectional = bidirectional\n",
        "\n",
        "\n",
        "#     def forward(self, texts):\n",
        "#         embedding = self.embed(texts)\n",
        "#         output, hidden = self.rnn(embedding)\n",
        "\n",
        "#         if self.bidirectional:\n",
        "#           a = hidden.view(self.num_layers, 2, texts.size(0), self.hidden_size)\n",
        "#           concatenate = torch.cat((a[-1][0], a[-1][1]), dim = 1)\n",
        "#         else:\n",
        "#           a = hidden.view(self.num_layers, 1, texts.size(0), self.hidden_size)\n",
        "#           concatenate = torch.cat(a[-1], dim = 1)\n",
        "#         drop = self.dropout(concatenate)\n",
        "#         return self.linear(drop)"
      ],
      "metadata": {
        "id": "5MbnjdST_vZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDLTiJMyoLxJ"
      },
      "source": [
        "##Sanity Check: RNN Model\n",
        "\n",
        "The code below runs a sanity check for your `RNN` class. The tests are similar to the hidden ones in Gradescope. However, note that passing the sanity check does <b>not</b> guarantee that you will pass the autograder; it is intended to help you debug."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Duq7X2ClwXga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "905100c6-504e-4d31-aa95-3de120cd832f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- TEST: Number of Model Parameters (tests __init__(...)) ---\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 44546\tYour Num. Params: 44546\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 44676\tYour Num. Params: 44676\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 27202\tYour Num. Params: 27202\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 27268\tYour Num. Params: 27268\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 82178\tYour Num. Params: 82178\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 82308\tYour Num. Params: 82308\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 39874\tYour Num. Params: 39874\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 39940\tYour Num. Params: 39940\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 1620610\tYour Num. Params: 1620610\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 1621636\tYour Num. Params: 1621636\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 621698\tYour Num. Params: 621698\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 622212\tYour Num. Params: 622212\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 3986050\tYour Num. Params: 3986050\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 3987076\tYour Num. Params: 3987076\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 1411202\tYour Num. Params: 1411202\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 1411716\tYour Num. Params: 1411716\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 101762\tYour Num. Params: 101762\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 101892\tYour Num. Params: 101892\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 79810\tYour Num. Params: 79810\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 79876\tYour Num. Params: 79876\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 139394\tYour Num. Params: 139394\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 139524\tYour Num. Params: 139524\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 92482\tYour Num. Params: 92482\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 92548\tYour Num. Params: 92548\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 1742338\tYour Num. Params: 1742338\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 1743364\tYour Num. Params: 1743364\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 706562\tYour Num. Params: 706562\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 707076\tYour Num. Params: 707076\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 4107778\tYour Num. Params: 4107778\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 4108804\tYour Num. Params: 4108804\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 1496066\tYour Num. Params: 1496066\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 1496580\tYour Num. Params: 1496580\n",
            "\n",
            "--- TEST: Output shape of forward(...) ---\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Test init\n",
        "    inputs = [{'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}]\n",
        "    expected_outputs = [44546, 44676, 27202, 27268, 82178, 82308, 39874, 39940, 1620610, 1621636, 621698, 622212, 3986050, 3987076, 1411202, 1411716, 101762, 101892, 79810, 79876, 139394, 139524, 92482, 92548, 1742338, 1743364, 706562, 707076, 4107778, 4108804, 1496066, 1496580]\n",
        "\n",
        "    sanityCheckModel(inputs, RNN, expected_outputs, \"init\", None)\n",
        "    print()\n",
        "\n",
        "    # Test forward\n",
        "    inputs = [{'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}]\n",
        "    expected_outputs = [torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4])]\n",
        "    sanity_dataset = TextDataset(train_data, 'train', 5, 150)\n",
        "    sanity_loader = torch.utils.data.DataLoader(sanity_dataset, batch_size=50, shuffle=True, num_workers=2, drop_last=True)\n",
        "\n",
        "    sanityCheckModel(inputs, RNN, expected_outputs, \"forward\", sanity_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baD8lYAytdTV"
      },
      "source": [
        "## Train RNN Model\n",
        "First, we initialize the train and test dataloaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCzNm8LDM5aT"
      },
      "outputs": [],
      "source": [
        "if __name__=='__main__':\n",
        "    THRESHOLD = 5 # Don't change this\n",
        "    MAX_LEN = 200 # Don't change this\n",
        "    BATCH_SIZE = 32 # Feel free to try other batch sizes\n",
        "\n",
        "    train_dataset = TextDataset(train_data, 'train', THRESHOLD, MAX_LEN)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n",
        "\n",
        "    test_dataset = TextDataset(test_data, 'test', THRESHOLD, MAX_LEN, train_dataset.idx2word, train_dataset.word2idx)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=1, drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp5pAz8emxi2"
      },
      "source": [
        "Now you can instantiate your model. We provide you with some recommended hyperparameters; you should be able to get the desired accuracy with these, but feel free to play around with them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CA-UairGErap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9969aaa9-bc4d-4729-bb85-999360e7b3f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 4,300,546 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "if __name__=='__main__':\n",
        "    rnn_model = RNN(vocab_size = train_dataset.vocab_size, # Don't change this\n",
        "                embed_size = 128, \n",
        "                hidden_size = 128, \n",
        "                num_layers = 2,\n",
        "                bidirectional = True,\n",
        "                dropout = 0.5,\n",
        "                num_classes = 2, # Don't change this\n",
        "                pad_idx = train_dataset.word2idx[PAD]) # Don't change this\n",
        "\n",
        "    # Put your model on device\n",
        "    rnn_model = rnn_model.to(DEVICE)\n",
        "\n",
        "    print('The model has {:,d} trainable parameters'.format(count_parameters(rnn_model)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqngFY4MoLec"
      },
      "source": [
        "Here, we create the criterion and optimizer; as with the CNN, we use cross-entropy loss and Adam optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "em6Rs58OlJ3Z"
      },
      "outputs": [],
      "source": [
        "if __name__=='__main__':    \n",
        "    LEARNING_RATE = 5e-4 # Feel free to try other learning rates\n",
        "\n",
        "    # Define your loss function\n",
        "    criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "\n",
        "    # Define your optimizer\n",
        "    optimizer = optim.Adam(rnn_model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEPsi3choUm5"
      },
      "source": [
        "Finally, we can train the model. We use the same `train_model(...)` function that we defined for the CNN. If the model is implemented correctly and you're using the GPU, this cell should take around <b>2 minutes</b> (or less). Feel free to change the number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NR8Wckf0l2G7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "246f4f6d52ff4e51be5842b3b7b033c8",
            "e35e0ac1e979473da050759653157f3b",
            "10095e24f45e48d5a995d1f91a6b5660",
            "0075cd82c3474a1bad80a30b830e69da",
            "b832de73a91b4c4bbf2e6ef89cbd2199",
            "f441d3b3d3ea41a49822e350a2956134",
            "31beb2198acf4e359e7e4fb1bf68cc23",
            "acfbafdbe13646e19ffd36c22cc5829d",
            "47da64fe308340e28ca166aae1b6dcdd",
            "8da2af72bc9d49328057d4eb3ac5b37f",
            "34357b45963e4457a9be1a794487b122"
          ]
        },
        "outputId": "29346d2b-1c56-42e3-9e34-7f6b9f9cf3c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "246f4f6d52ff4e51be5842b3b7b033c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]\t Epoch:  1\t Loss: 0.6599\t Train Accuracy: 59.41%\n",
            "[TRAIN]\t Epoch:  2\t Loss: 0.4936\t Train Accuracy: 76.55%\n",
            "[TRAIN]\t Epoch:  3\t Loss: 0.3606\t Train Accuracy: 84.44%\n",
            "[TRAIN]\t Epoch:  4\t Loss: 0.2724\t Train Accuracy: 88.81%\n",
            "[TRAIN]\t Epoch:  5\t Loss: 0.1938\t Train Accuracy: 92.69%\n",
            "[TRAIN]\t Epoch:  6\t Loss: 0.1260\t Train Accuracy: 95.54%\n",
            "Model Trained!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__=='__main__':    \n",
        "    N_EPOCHS = 6 # Feel free to change this\n",
        "    \n",
        "    # train model for N_EPOCHS epochs\n",
        "    train_model(rnn_model, N_EPOCHS, train_loader, optimizer, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-SRIFfooYk6"
      },
      "source": [
        "## Evaluate RNN Model [20 points]\n",
        "\n",
        "Now we can evaluate the RNN. \n",
        "\n",
        "To pass the autograder for the RNN, you will need to achieve **82% accuracy** on the hidden test set on Gradescope. Note that the Gradescope test set is very similar, and the accuracies between the two datasets should be comparable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYon4AbHl5_M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659,
          "referenced_widgets": [
            "bcfbcfac868e4d52b63c3c63420e5420",
            "7c5441af769d4c77a38825e0fc8beb0f",
            "6057ff5dce654118965d7ef6a63aadb2",
            "8294970bf44d42f4bbf070f9432cf11e",
            "27265c1c2ca648d79dbf8bd85a9de8a0",
            "8533b250ff254c6db52b2da4289e8f82",
            "d14ea4bbef3f4434b6bc19dfc98c7c32",
            "fcacd68356554ccf93d65e7eb9488d93",
            "a0df5129f4e84746b21c932645acadfb",
            "33d819ef81564fe2b53b5ada41f26ad1",
            "e23de5b689a74f48a1fdde5c925a72f6"
          ]
        },
        "outputId": "0ab51440-6237-4b66-d9a5-8a5125ceaea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating performance on the test dataset...\n",
            "\n",
            "SOME PREDICTIONS FROM THE MODEL:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcfbcfac868e4d52b63c3c63420e5420"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <UNK> lesson that some film makers ( particularly those inspired by <UNK> ) need to know - just ' style ' does not sell . <UNK> guess <UNK> when translated will mean style . <UNK> , if you are hell bent on selling style , that does not spare you from having a decent story.<br /><br <UNK> has some story which could have <UNK> with some better director . <UNK> it is not slick . <UNK> example , all three - <UNK> , <UNK> and <UNK> - are <UNK> at different points in the story . <UNK> this setup is not utilized to properly . <UNK> could have been a better mix and match of their <UNK> . <UNK> sequences are from the <UNK> /><br <UNK> of the film is awful . <UNK> think <UNK> <UNK> just sleep walked through this film . <UNK> have put up a good score but it does not belong to this film . <UNK> is there a <UNK> song ( <UNK> <UNK> ) in <UNK> ? <UNK> is the cool <UNK> song ( <UNK> <UNK> <UNK> ) not on <UNK> <UNK> when he is the one who is <UNK> crazy ? <br /><br <UNK>\n",
            "Prediction: 0 \tCorrect Output: 0 \n",
            "\n",
            "Input: <UNK> you liked \" <UNK> with \" you'll like this one . <UNK> has the same lousy camera-work and soundtrack , and it has the same non-existent plot and suspenseful moments.<br /><br <UNK> also has <UNK> <UNK> , so if you like <UNK> \" <UNK> of the dead \" or <UNK> and <UNK> ' \" <UNK> <UNK> <UNK> <UNK> \" you're in for a treat . <UNK> is an icon and a very good actor as well.<br /><br <UNK> , seriously . <UNK> movie is definitely the <UNK> movie <UNK> seen in a long time , and <UNK> seen quite a few movies -- bad ones as well . <UNK> can tell you that <UNK> find most horror movies entertaining in some respect , but this was just a pure waste of time.<br /><br <UNK> only reason why <UNK> gave this movie 2 instead of 1 , was the naked chicks and the hot action with all the <UNK> plastic <UNK> . <UNK> , <UNK> just kidding . <UNK> must have missed before <UNK> hit \" submit \" on the vote form.<br /><br <UNK> away , even though it has sexy girls with teeth on the cover !\n",
            "Prediction: 0 \tCorrect Output: 0 \n",
            "\n",
            "Input: <UNK> coming attractions to \" <UNK> <UNK> \" make it seem like a decent horror mystery/thriller , but what we get is a plot that has potential to be excellent all thrown together to form a pile of garbage.<br /><br <UNK> off the whole movie consists of terrible dialogue and god awful special affects . <UNK> acting was also nothing to be proud of , but <UNK> <UNK> ( <UNK> think <UNK> spelled that right. ) saved the movie in this category.<br /><br <UNK> heaven's sake : <UNK> <UNK> <UNK> <UNK> !\n",
            "Prediction: 0 \tCorrect Output: 0 \n",
            "\n",
            "Input: <UNK> a promising first 25 minutes that makes you feel all warm inside , you're pretty convinced that this will be a great romantic comedy . <UNK> the movie takes a turn for the worse . <br /><br <UNK> warm feeling might still be there , but as others has said : <UNK> plot becomes so unbelievable and artificial that it's almost unbearable to watch . <br /><br <UNK> movie gets sped up , and you get the impression that you're either fast forwarding through it , or that the producers decided to fit it in less than <UNK> and had to cut a lot of scenes out.<br /><br <UNK> isn't a goal onto itself , but as a viewer , <UNK> pretty convinced that this comedy isn't intentionally unrealistic , it just happens to be.<br /><br <UNK> the plus side , this movie has a couple of nice interiors , and despite the bad script , <UNK> think that the actors performances are mainly good . <UNK> <UNK> could rate the first 25 minutes only , <UNK> probably give it an eight . <UNK> it is now , it gets a four . <UNK> that's being nice ! <br\n",
            "Prediction: 0 \tCorrect Output: 0 \n",
            "\n",
            "Input: <UNK> who is a sucker for 1920s jazz , 1920s dress , the <UNK> , and <UNK> <UNK> ( e.g . me , on all counts ) will want to like this movie . <UNK> the sad fact is that that's all there is . <UNK> plot is banal and obvious , the acting mostly either awful or playing to the farcical side of the goings-on , and when the whole thing's over there is not much left but the impression of mirrors and smoke . <UNK> is a beautifully made bad movie .\n",
            "Prediction: 0 \tCorrect Output: 0 \n",
            "\n",
            "Input: <UNK> offensively over-the-top action <UNK> <UNK> <UNK> <UNK> seemed to catch the mood of the <UNK> at the time of it's release in the <UNK> right-wing <UNK> and virulent <UNK> feelings still not finished <UNK> the emergence of a certain <UNK> <UNK> in the heart of the ' <UNK> <UNK> ' in <UNK> would soon render these types of films <UNK> <UNK> himself eventually admitted this <UNK> /><br <UNK> that <UNK> can be most grateful to ' <UNK> for his <UNK> <UNK> with the <UNK> his policies of ' <UNK> even his support of democracy being restored to the <UNK> <UNK> countries in the former <UNK> <UNK> <UNK> the final <UNK> of <UNK> <UNK> adventures like <UNK> first <UNK> film was hardly <UNK> at least was a mildly literate and adequate action thriller with a not too bad <UNK> this <UNK> sense of even the <UNK> conviction is instantly jettisoned for <UNK> plotting and incident in which <UNK> single-handedly takes on scores of <UNK> stereotyped <UNK> and <UNK> troops to rescue <UNK> <UNK> ten years after the conflict <UNK> the <UNK> on the losing side.<br /><br <UNK> the reason why the film was a huge box-office success was to let\n",
            "Prediction: 0 \tCorrect Output: 0 \n",
            "\n",
            "Input: <UNK> <UNK> fantasy is the second in the popular by flawed <UNK> series put out by <UNK> . <UNK> is a first-class adventure for many reasons , <UNK> <UNK> photography , strong imaginative qualities , a delightful cast , good <UNK> locales and a very exciting storyline . <UNK> <UNK> plays <UNK> , a <UNK> <UNK> sort unlike <UNK> <UNK> <UNK> ' creation ; but he is honest , loyal , brave and very courageous , and he needs to be during this narrative . <UNK> <UNK> <UNK> , his wife who had been <UNK> <UNK> in the novels , <UNK> <UNK> is very attractive and lively , as well as being athletic where the script calls for that quality . <UNK> effect of the lighting , the <UNK> and clever sets is quite unusual . <UNK> is an outdoor adventure filmed on the <UNK> <UNK> which really works . <UNK> fabulous <UNK> <UNK> is a remote locale which allows <UNK> and <UNK> to live <UNK> ; but into their <UNK> come people searching from them , <UNK> of a civilization <UNK> has left behind and into which <UNK> could not really be comfortably <UNK> . <UNK> is <UNK> <UNK>\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "Input: <UNK> amazing this film is ! <UNK> seen it over and over throughout the years and <UNK> always spellbound by it . <UNK> reason why the film is so easy to re-watch is , of course , the arresting performance given by the young <UNK> <UNK> . <UNK> not only steals every scene that she's in , but is actually much prettier and better photographed here ( not to mention sexier ) than she was in any of the films that she had made thus far at her home studio , <UNK> <UNK> ( this film was made by <UNK> . <UNK> <UNK> . <UNK> wears a very flattering make-up and has very attractive hairstyles and oh , those lovely big eyes ( especially , in the restaurant scenes that take place in <UNK> <UNK> . <UNK> body was so <UNK> when she was young . <UNK> a load of it in the cheap <UNK> that she wears for her big explosive confrontation scene with <UNK> <UNK> . <UNK> oh boy , she is an absolute powerhouse in that scene . <UNK> is a little too nervous throughout , but he does captures the hero's sensitivity . <UNK> <UNK> scores\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "Input: <UNK> you're a fan of <UNK> horror , then you're definitely absolutely guaranteed to <UNK> this wondrous <UNK> 60's film \" <UNK> of <UNK> . <UNK> really talking about creepily <UNK> doors , eerie portraits that appear to be moving , spontaneously dying candles although there's no wind and smoke coming from underneath heavy wooden chamber doors . <UNK> in terms of atmosphere and style , this masterful piece of <UNK> film-making is one of the best out there ; just one tiny league below landmarks such as \" <UNK> <UNK> , \" <UNK> <UNK> <UNK> of <UNK> \" and \" <UNK> of the <UNK> <UNK> . <UNK> prominent directors duo <UNK> <UNK> ( <UNK> <UNK> <UNK> , \" <UNK> ) and <UNK> <UNK> ( <UNK> <UNK> , \" <UNK> <UNK> ) are successful in all areas , including a powerful plot ( one that is genuinely nightmare <UNK> , <UNK> scenery and filming locations , stylish black and white photography , spine-chilling music and a brilliant gathering of talented performers . <UNK> <UNK> , starlet of the aforementioned \" <UNK> <UNK> \" and <UNK> <UNK> number one , shines brightly again as a <UNK> tormented character and she's literally\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "Input: <UNK> recently stumbled across this film on <UNK> five minutes into it , while on vacation in <UNK> . ( hey there has to be some down time in the hotel , right? ) <UNK> was initially surprised to see <UNK> <UNK> <UNK> in any feature length film on <UNK> . <UNK> mean \" <UNK> <UNK> <UNK> \" isn't <UNK> old already , is it?<br /><br <UNK> <UNK> stuck with it , and was thoroughly surprised and entertained . <UNK> plays her role as the psychotic <UNK> excellently . <UNK> supporting cast ( <UNK> , the ex-con boyfriend ; <UNK> , her best friend ; and her <UNK> parents ) all added a great degree of believability . <UNK> twist at the end was a nice closure to this tale of the girl who always seemed to be one step ahead of <UNK> /><br <UNK> you get a chance , check it out!<br /><br />\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "[TEST]\t Loss: 0.5092\t Accuracy: 82.14%\n"
          ]
        }
      ],
      "source": [
        "if __name__=='__main__':    \n",
        "    evaluate(rnn_model, test_loader, criterion, use_tqdm=True) # Compute test data accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WQAV6O2xHvS"
      },
      "source": [
        "# What to Submit\n",
        "\n",
        "To submit the assignment, download this notebook as a <TT>.py</TT> file. You can do this by going to <TT>File > Download > Download .py</TT>. Then (optionally) rename it to `hwk2.py`.\n",
        "\n",
        "You will also need to save the `cnn_model` and `rnn_model`. You can run the cell below to do this. After you save the files to your Google Drive, you need to manually download the files to your computer, and then submit them to the autograder.\n",
        "\n",
        "You will submit the following files to the autograder:\n",
        "1.   `hwk2.py`, the download of this notebook as a `.py` file (**not** a `.ipynb` file)\n",
        "1.   `cnn.pt`, the saved version of your `cnn_model`\n",
        "1.   `rnn.pt`, the saved version of your `rnn_model`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abbbMNi8X_ai",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79e5bf1c-cc95-4f55-8851-a702c36f7162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "Saving CNN model....\n",
            "Saving RNN model....\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "if __name__=='__main__':\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print()\n",
        "\n",
        "    try:\n",
        "        cnn_model is None\n",
        "        cnn_exists = True\n",
        "    except:\n",
        "        cnn_exists = False\n",
        "\n",
        "    try:\n",
        "        rnn_model is None\n",
        "        rnn_exists = True\n",
        "    except:\n",
        "        rnn_exists = False\n",
        "\n",
        "    if cnn_exists:\n",
        "        print(\"Saving CNN model....\") \n",
        "        torch.save(cnn_model, \"drive/My Drive/cnn.pt\")\n",
        "    if rnn_exists:\n",
        "        print(\"Saving RNN model....\") \n",
        "        torch.save(rnn_model, \"drive/My Drive/rnn.pt\")\n",
        "    print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v4o5fRQELX7G"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "252361cf26b84811b14b97c875e3a054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b85b45f79664d73a2d66afcac3177d9",
              "IPY_MODEL_7f5fdc04779b4e2d806593408aa10671",
              "IPY_MODEL_acd0ff48aab640cc98225bbbd0870c2d"
            ],
            "layout": "IPY_MODEL_25cedf7910404db5946ff5f475ac07d0"
          }
        },
        "4b85b45f79664d73a2d66afcac3177d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_376c9e791c5d4609a0d2b1919ceb25c4",
            "placeholder": "​",
            "style": "IPY_MODEL_168e577de44e488792ccf6124b80656d",
            "value": "100%"
          }
        },
        "7f5fdc04779b4e2d806593408aa10671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f73120b205e24bf7a48acf614a58a5b8",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afdbf11060354eb09c26465ef5d6a404",
            "value": 10
          }
        },
        "acd0ff48aab640cc98225bbbd0870c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9166c0a7e9dd43caab4eefc8b71c3600",
            "placeholder": "​",
            "style": "IPY_MODEL_5253448fe81f42ae84f5172d07e65557",
            "value": " 10/10 [04:00&lt;00:00, 23.54s/it]"
          }
        },
        "25cedf7910404db5946ff5f475ac07d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "376c9e791c5d4609a0d2b1919ceb25c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "168e577de44e488792ccf6124b80656d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f73120b205e24bf7a48acf614a58a5b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afdbf11060354eb09c26465ef5d6a404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9166c0a7e9dd43caab4eefc8b71c3600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5253448fe81f42ae84f5172d07e65557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a11e8081abb4bfab3985cab31d7e6c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26631291ac2649a7b295d0f16b902920",
              "IPY_MODEL_f2c354dc64a44e69a607b4f6314a41f6",
              "IPY_MODEL_c0be46b9526643fca7896ae72ee11b54"
            ],
            "layout": "IPY_MODEL_57c33af500ec4453b9fbc6f1274bab21"
          }
        },
        "26631291ac2649a7b295d0f16b902920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9370e6d571843448d49e601c178b452",
            "placeholder": "​",
            "style": "IPY_MODEL_0359196e046a436a90b997351c7c0e23",
            "value": "100%"
          }
        },
        "f2c354dc64a44e69a607b4f6314a41f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55e314c1f9034476afe2b23383943a15",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af430c9b0fc440eebacf64f5c18832bd",
            "value": 5000
          }
        },
        "c0be46b9526643fca7896ae72ee11b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0178870fca9249fbb40fa1902fc805e1",
            "placeholder": "​",
            "style": "IPY_MODEL_aaa8eda3dc404b95b6efa0004453f95d",
            "value": " 5000/5000 [00:15&lt;00:00, 335.02it/s]"
          }
        },
        "57c33af500ec4453b9fbc6f1274bab21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9370e6d571843448d49e601c178b452": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0359196e046a436a90b997351c7c0e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55e314c1f9034476afe2b23383943a15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af430c9b0fc440eebacf64f5c18832bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0178870fca9249fbb40fa1902fc805e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaa8eda3dc404b95b6efa0004453f95d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "246f4f6d52ff4e51be5842b3b7b033c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e35e0ac1e979473da050759653157f3b",
              "IPY_MODEL_10095e24f45e48d5a995d1f91a6b5660",
              "IPY_MODEL_0075cd82c3474a1bad80a30b830e69da"
            ],
            "layout": "IPY_MODEL_b832de73a91b4c4bbf2e6ef89cbd2199"
          }
        },
        "e35e0ac1e979473da050759653157f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f441d3b3d3ea41a49822e350a2956134",
            "placeholder": "​",
            "style": "IPY_MODEL_31beb2198acf4e359e7e4fb1bf68cc23",
            "value": "100%"
          }
        },
        "10095e24f45e48d5a995d1f91a6b5660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acfbafdbe13646e19ffd36c22cc5829d",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47da64fe308340e28ca166aae1b6dcdd",
            "value": 6
          }
        },
        "0075cd82c3474a1bad80a30b830e69da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8da2af72bc9d49328057d4eb3ac5b37f",
            "placeholder": "​",
            "style": "IPY_MODEL_34357b45963e4457a9be1a794487b122",
            "value": " 6/6 [00:50&lt;00:00,  8.24s/it]"
          }
        },
        "b832de73a91b4c4bbf2e6ef89cbd2199": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f441d3b3d3ea41a49822e350a2956134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31beb2198acf4e359e7e4fb1bf68cc23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acfbafdbe13646e19ffd36c22cc5829d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47da64fe308340e28ca166aae1b6dcdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8da2af72bc9d49328057d4eb3ac5b37f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34357b45963e4457a9be1a794487b122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcfbcfac868e4d52b63c3c63420e5420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c5441af769d4c77a38825e0fc8beb0f",
              "IPY_MODEL_6057ff5dce654118965d7ef6a63aadb2",
              "IPY_MODEL_8294970bf44d42f4bbf070f9432cf11e"
            ],
            "layout": "IPY_MODEL_27265c1c2ca648d79dbf8bd85a9de8a0"
          }
        },
        "7c5441af769d4c77a38825e0fc8beb0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8533b250ff254c6db52b2da4289e8f82",
            "placeholder": "​",
            "style": "IPY_MODEL_d14ea4bbef3f4434b6bc19dfc98c7c32",
            "value": "100%"
          }
        },
        "6057ff5dce654118965d7ef6a63aadb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcacd68356554ccf93d65e7eb9488d93",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0df5129f4e84746b21c932645acadfb",
            "value": 5000
          }
        },
        "8294970bf44d42f4bbf070f9432cf11e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33d819ef81564fe2b53b5ada41f26ad1",
            "placeholder": "​",
            "style": "IPY_MODEL_e23de5b689a74f48a1fdde5c925a72f6",
            "value": " 5000/5000 [00:18&lt;00:00, 282.59it/s]"
          }
        },
        "27265c1c2ca648d79dbf8bd85a9de8a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8533b250ff254c6db52b2da4289e8f82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d14ea4bbef3f4434b6bc19dfc98c7c32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcacd68356554ccf93d65e7eb9488d93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0df5129f4e84746b21c932645acadfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33d819ef81564fe2b53b5ada41f26ad1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e23de5b689a74f48a1fdde5c925a72f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}